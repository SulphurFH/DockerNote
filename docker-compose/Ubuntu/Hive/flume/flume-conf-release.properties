tier1.sources = s_kafka_event
tier1.channels = c_event
tier1.sinks = k_event_hdfs

tier1.sources.s_kafka_event.type = org.apache.flume.source.kafka.KafkaSource
tier1.sources.s_kafka_event.batchSize = 100
tier1.sources.s_kafka_event.kafka.bootstrap.servers = xxxx:9092
tier1.sources.s_kafka_event.kafka.topics = scievents-topic
tier1.sources.s_kafka_event.kafka.consumer.group.id = xxxxx
tier1.sources.s_kafka_event.kafka.consumer.auto.offset.reset=earliest
tier1.sources.s_kafka_event.interceptors=i1
tier1.sources.s_kafka_event.interceptors.i1.type=com.xxx.flume.interceptor.EventLogJson$Builder
tier1.sources.s_kafka_event.channels = c_event

tier1.sinks.k_event_hdfs.type = hdfs
tier1.sinks.k_event_hdfs.hdfs.path = /user/useranalysis/eventlog/%{logType}/%{year}%{month}
tier1.sinks.k_event_hdfs.hdfs.filePrefix = %{logType}_%Y%m%d_%H
tier1.sinks.k_event_hdfs.hdfs.useLocalTimeStamp = true
tier1.sinks.k_event_hdfs.hdfs.fileSuffix = .log
tier1.sinks.k_event_hdfs.hdfs.inUsePrefix = .
tier1.sinks.k_event_hdfs.hdfs.inUseSuffix = .tmp
tier1.sinks.k_event_hdfs.hdfs.fileType = DataStream
tier1.sinks.k_event_hdfs.hdfs.rollCount = 1000000
tier1.sinks.k_event_hdfs.hdfs.rollSize = 128000000
tier1.sinks.k_event_hdfs.hdfs.rollInterval = 3600
tier1.sinks.k_event_hdfs.hdfs.idleTimeout = 600
tier1.sinks.k_event_hdfs.hdfs.minBlockReplicas = 1
tier1.sinks.k_event_hdfs.channel = c_event

tier1.channels.c_event.type = memory
tier1.channels.c_event.capacity = 20000
